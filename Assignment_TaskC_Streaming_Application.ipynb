{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f08a066079a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0mssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Run stream for 10 minutes just in case no detection of producer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;31m# ssc.awaitTermination()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0mssc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopSparkContext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstopGraceFully\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36msignal_handler\u001b[0;34m(signal, frame)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0msignal_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancelAllJobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;31m# see http://stackoverflow.com/questions/23206787/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.3.0 pyspark-shell'\n",
    "\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pygeohash as gh\n",
    "from pprint import pprint\n",
    "from pymongo import MongoClient\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "def join(t1,t2): # Define a \"join\" method for calling in function \"sendDataToDB\"\n",
    "    t2.pop('geohash') # reduce the repeating  \n",
    "    t2.pop('fire')\n",
    "    t2.pop('latitude')\n",
    "    t2.pop('longitude')\n",
    "    t1[\"fire_data\"].append(t2) #append the second dict to list so that form the embeded data model\n",
    "    t1[\"fire\"] = 'true' # set True because once join with data from producer2 or producer3, it means there is a fire\n",
    "    return t1\n",
    "\n",
    "def sendDataToDB(iter):\n",
    "    client = MongoClient()\n",
    "    db = client.fit5148_assignment_db # Using fit5148_assignment_db in mongoDB\n",
    "    all_data = db.all_data  #Set 3 collections, all_data is for storing all data\n",
    "    fire_data = db.fire_data  #fire_data is for storing the fire record in mongoDB\n",
    "    join_data = db.join_data  #join_data is for storing the join results(once there is join result) in mongoDB\n",
    "    producer1 = []  # Set lists to store the data from producer1,2,3 \n",
    "    producer2 = []\n",
    "    producer3 = []\n",
    "    fire_list = [] #fire_list is for storing the fire record\n",
    "    join_list = [] #join_list is for storing join result\n",
    "    for record in iter: \n",
    "        Data = json.loads(record[1])\n",
    "        jsonData = {}\n",
    "        jsonData[\"sender_id\"] = Data.get(\"sender_id\")\n",
    "        jsonData[\"time\"] = Data.get(\"create_time\")\n",
    "        \n",
    "        # This section is used for reading data from kafak producer\n",
    "        \n",
    "        if jsonData[\"sender_id\"] == \"Producer1\":  \n",
    "            jsonData[\"precipitation\"] = Data.get(\"data\").get(\"precipitation \")\n",
    "            jsonData[\"relative_humidity\"] = Data.get(\"data\").get(\"relative_humidity\")\n",
    "            jsonData[\"max_wind_speed\"] = Data.get(\"data\").get(\"max_wind_speed\")\n",
    "            jsonData[\"longitude\"] = Data.get(\"data\").get(\"longitude\")\n",
    "            jsonData[\"windspeed_knots\"] = Data.get(\"data\").get(\"windspeed_knots\")\n",
    "            jsonData[\"latitude\"] = Data.get(\"data\").get(\"latitude\")\n",
    "            jsonData[\"air_temperature_celcius\"] = Data.get(\"data\").get(\"air_temperature_celcius\")\n",
    "            jsonData[\"geohash\"] = gh.encode(jsonData[\"longitude\"],jsonData[\"latitude\"],precision=5)\n",
    "            jsonData[\"fire_data\"] = []\n",
    "            jsonData[\"fire\"]=\"false\"\n",
    "        else:\n",
    "            jsonData[\"surface_temperature_celcius\"] = Data.get(\"data\").get(\"surface_temperature_celcius\")\n",
    "            jsonData[\"latitude\"] = Data.get(\"data\").get(\"latitude\")\n",
    "            jsonData[\"confidence\"] = Data.get(\"data\").get(\"confidence\")\n",
    "            jsonData[\"longitude\"] = Data.get(\"data\").get(\"longitude\")\n",
    "            jsonData[\"geohash\"] = gh.encode(jsonData[\"longitude\"],jsonData[\"latitude\"],precision=5)\n",
    "            jsonData[\"fire\"]=\"true\"\n",
    "        # Because data from different producer, it will have different document, so we consider 2 situations\n",
    "        if jsonData[\"sender_id\"] == \"Producer1\":\n",
    "            producer1.append(jsonData)\n",
    "        if jsonData[\"sender_id\"] == \"Producer2\":\n",
    "            producer2.append(jsonData)\n",
    "            fire1 = jsonData.copy()\n",
    "            fire_list.append(fire1)\n",
    "        if jsonData[\"sender_id\"] == \"Producer3\":\n",
    "            producer3.append(jsonData) \n",
    "            fire1 = jsonData.copy() \n",
    "            fire_list.append(fire1)\n",
    "            \n",
    "        # This is used to store data by the different producer\n",
    "        # we copy the fire record to the fire_list because we don't hope the pop() in join() function \n",
    "        # will change the original data\n",
    "        \n",
    "    amount = len(producer1)+len(producer2)+len(producer3)\n",
    "    if amount >= 2: # This means there be 2 or more records in stream application\n",
    "        # We do the average option for the data with same geohash from producer2 and producer3\n",
    "        if len(producer2) > 0 and len(producer3) > 0: \n",
    "            for record2 in producer2:\n",
    "                for record3 in producer3:\n",
    "                    if record2[\"geohash\"] == record3[\"geohash\"]:\n",
    "                            record2['surface_temperature_celcius'] = 0.5* (record2['surface_temperature_celcius'] \\\n",
    "                                +record3['surface_temperature_celcius'])\n",
    "                            record2['confidence'] = 0.5* (record2['confidence'] +record3['confidence'])\n",
    "                            record3['surface_temperature_celcius'] = record2['surface_temperature_celcius']\n",
    "                            record3['confidence'] = record2['confidence']\n",
    "        # We dont remove the record, we just update the average data to original data.\n",
    "        \n",
    "    for record1 in producer1:\n",
    "        if len(producer2) == 0 and len(producer3) > 0: # If there is data from producer1 and producer3\n",
    "            for record3 in producer3:\n",
    "                if record1[\"geohash\"] == record3[\"geohash\"]:\n",
    "                    record1 = join(record1,record3) # Call join() function we write previous\n",
    "                    join_list.append(record1)\n",
    "                    producer3.remove(record3)\n",
    "        if len(producer2) > 0 and len(producer3) == 0: # If there is data from producer1 and producer2\n",
    "            for record2 in producer2:\n",
    "                if record1[\"geohash\"] == record2[\"geohash\"]:\n",
    "                    record1 = join(record1,record2)\n",
    "                    join_list.append(record1)\n",
    "                    producer2.remove(record2)\n",
    "        if len(producer2) > 0 and len(producer3) > 0: # If there is data from producer1,2,3\n",
    "            for record2 in producer2:\n",
    "                if record1[\"geohash\"] == record2[\"geohash\"]:\n",
    "                    record1 = join(record1,record2)\n",
    "                    join_list.append(record1)\n",
    "                    producer2.remove(record2)\n",
    "            for record3 in producer3:\n",
    "                if record1[\"geohash\"] == record3[\"geohash\"]:\n",
    "                    record1 = join(record1,record3)\n",
    "                    join_list.append(record1)\n",
    "                    producer3.remove(record3)\n",
    "                else:\n",
    "                    if len(record1['fire_data']>0):\n",
    "                        join_list.append(record1)                    \n",
    "                    \n",
    "    iter2 = []\n",
    "    iter2 = producer1 + producer2 + producer3    \n",
    "            \n",
    "    for item in iter2: # insert all data into mongoDB\n",
    "        try:\n",
    "            all_data.insert(item)\n",
    "        except Exception as ex:\n",
    "            print(\"Exception Occured. Message: {0}\".format(str(ex)))\n",
    "            \n",
    "    for item2 in fire_list: #insert fire records into mongoDB\n",
    "        try:\n",
    "            fire_data.insert(item2)\n",
    "        except Exception as ex:\n",
    "            print(\"Exception Occured. Message: {0}\".format(str(ex)))  \n",
    "            \n",
    "    for item3 in join_list: # insert join result into mongoDB\n",
    "        try:\n",
    "            join_data.insert(item3)\n",
    "        except Exception as ex:\n",
    "            print(\"Exception Occured. Message: {0}\".format(str(ex)))\n",
    "            \n",
    "    client.close()\n",
    "\n",
    "batch_interval = 10 #set the batch interval to 10 \n",
    "topic = \"Producer\"\n",
    "\n",
    "conf = SparkConf().setAppName(\"KafkaStreamProcessor\").setMaster(\"local[2]\") # Set 2 execution threads\n",
    "sc = SparkContext.getOrCreate()\n",
    "if sc is None:\n",
    "    sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"WARN\")\n",
    "ssc = StreamingContext(sc, batch_interval)\n",
    "    \n",
    "kafkaStream = KafkaUtils.createDirectStream(ssc, [topic], {\n",
    "                        'bootstrap.servers':'127.0.0.1:9092', \n",
    "                        'group.id':'week11-group', \n",
    "                        'fetch.message.max.bytes':'15728640',\n",
    "                        'auto.offset.reset':'largest'})\n",
    "                        # Group ID is completely arbitrary\n",
    "\n",
    "lines = kafkaStream.foreachRDD(lambda rdd: rdd.foreachPartition(sendDataToDB))\n",
    "\n",
    "ssc.start()\n",
    "time.sleep(600) # Run stream for 10 minutes just in case no detection of producer\n",
    "# ssc.awaitTermination()\n",
    "ssc.stop(stopSparkContext=True,stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient() #Drop the collections in mongoDB when necessary\n",
    "db = client.fit5148_assignment_db\n",
    "db.all_data.drop()\n",
    "db.fire_data.drop()\n",
    "db.join_data.drop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
